{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dumi-coder/CeylonPulse/blob/main/CeylonPulse_DataCollection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4c5_rXPMheY"
      },
      "source": [
        "# CeylonPulse: Data Collection & Signal Detection\n",
        "\n",
        "**Real-Time Situational Awareness System for Sri Lanka**\n",
        "\n",
        "This notebook implements **Step 2** of the workflow:\n",
        "- Data Collection from multiple sources\n",
        "- Signal Detection using 40 PESTLE-based signals\n",
        "- Integration with TensorFlow models (for future steps)\n",
        "\n",
        "## Three Data Collection Methods:\n",
        "1. **Scraping** - RSS feeds, web scraping\n",
        "2. **API Responses** - Twitter, Google Trends\n",
        "3. **LLM Extraction** - Structure data + generate signals\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L97pqGooMhec"
      },
      "source": [
        "## Setup & Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovBrYlVGMhed",
        "outputId": "56558e5e-c651-462d-a5bc-01c4adc7e40d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/81.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ All packages installed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q requests beautifulsoup4 feedparser lxml\n",
        "!pip install -q pytrends python-dateutil\n",
        "!pip install -q pandas numpy\n",
        "\n",
        "# For TensorFlow (for future ML models)\n",
        "!pip install -q tensorflow\n",
        "\n",
        "# For Mistral 7B (optional - for local model, API doesn't need this)\n",
        "# !pip install -q transformers torch accelerate\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgc2yo-QMhef",
        "outputId": "67a30dfe-0064-4771-ad66-99f790316f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "‚úÖ Setup complete!\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive (optional - to save data)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set working directory\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz8Vuv0PMheg"
      },
      "source": [
        "## Import Libraries & Load 40 Signals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrQOj7VmMheh",
        "outputId": "99dd62d6-d970-468e-b548-a33bf1fdf622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded 40 PESTLE signals\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "from typing import List, Dict\n",
        "from collections import Counter\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load 40 PESTLE signals from SSD\n",
        "SIGNALS = [\n",
        "    \"Government Policy Announcements\", \"Cabinet/Parliament Decisions\",\n",
        "    \"Government Sector Strike Warnings\", \"Police/Security Alerts\",\n",
        "    \"Election-related Discussions\", \"Foreign Policy / International Agreements\",\n",
        "    \"Tax Revision Rumors\", \"Public Protests & Demonstrations\",\n",
        "    \"Inflation Mentions\", \"Fuel Shortage Mentions\", \"Dollar Rate Discussions\",\n",
        "    \"Tourism Search Trend (Google Trends)\", \"Food Price Spikes\",\n",
        "    \"Stock Market Volatility\", \"Foreign Investment News\",\n",
        "    \"Currency Black Market Mentions\", \"Crime & Safety Alerts\",\n",
        "    \"Public Sentiment (Social Media)\", \"Migration / Visa Interest\",\n",
        "    \"Public Health Discussions\", \"Viral Social Trends\",\n",
        "    \"Cultural Event Mentions\", \"Power Outages (CEB)\",\n",
        "    \"Telecom Outages\", \"Cyberattack Mentions\",\n",
        "    \"E-commerce Growth Indicators\", \"Digital Payments Failure Reports\",\n",
        "    \"New Regulations Affecting Businesses\", \"Court Rulings Impacting Industries\",\n",
        "    \"Import/Export Restriction Changes\", \"Customs/Port Delays\",\n",
        "    \"Rainfall Alerts\", \"Flood Warnings\", \"Heat Wave Alerts\",\n",
        "    \"Landslide Warnings\", \"Cyclone Updates\", \"Air Quality Index Changes\",\n",
        "    \"Drought Warnings\", \"Water Supply Cuts (NWSDB)\",\n",
        "    \"Coastal Erosion / Tsunami Alerts\"\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(SIGNALS)} PESTLE signals\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGiMaEw8Mhei"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L66bTqMDMhei",
        "outputId": "ad833ec6-f438-4e3f-9f69-7b990d9941de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Scraped 0 from Ada Derana, 20 from EconomyNext\n",
            "üìä Total articles: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-489744259.py:18: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  'scraped_at': datetime.utcnow().isoformat()\n"
          ]
        }
      ],
      "source": [
        "# RSS Feed Scraping\n",
        "import feedparser\n",
        "import requests\n",
        "\n",
        "def scrape_rss_feed(url):\n",
        "    \"\"\"Scrape RSS feed and return articles\"\"\"\n",
        "    try:\n",
        "        feed = feedparser.parse(url)\n",
        "        articles = []\n",
        "\n",
        "        for entry in feed.entries:\n",
        "            article = {\n",
        "                'title': entry.get('title', ''),\n",
        "                'link': entry.get('link', ''),\n",
        "                'description': entry.get('description', ''),\n",
        "                'published': entry.get('published', ''),\n",
        "                'source': feed.feed.get('title', 'Unknown'),\n",
        "                'scraped_at': datetime.utcnow().isoformat()\n",
        "            }\n",
        "            articles.append(article)\n",
        "\n",
        "        return articles\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping RSS feed {url}: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Data source URLs\n",
        "ADA_DERANA_RSS = 'https://www.adaderana.lk/rss.php'\n",
        "ECONOMYNEXT_RSS = 'https://economynext.com/rss'\n",
        "\n",
        "# Scrape RSS feeds\n",
        "ada_articles = scrape_rss_feed(ADA_DERANA_RSS)\n",
        "econ_articles = scrape_rss_feed(ECONOMYNEXT_RSS)\n",
        "\n",
        "all_scraped_articles = ada_articles + econ_articles\n",
        "print(f\"‚úÖ Scraped {len(ada_articles)} from Ada Derana, {len(econ_articles)} from EconomyNext\")\n",
        "print(f\"üìä Total articles: {len(all_scraped_articles)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfJDvG-_Mhek"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjWcJ8bRMhel",
        "outputId": "95cb67d4-dbd5-4aec-cfcf-74e5d5d7e842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error getting Google Trends: The request failed: Google returned a response with code 404\n",
            "‚úÖ Retrieved 0 trending searches\n"
          ]
        }
      ],
      "source": [
        "# Google Trends API\n",
        "from pytrends.request import TrendReq\n",
        "\n",
        "def get_google_trends(geo='LK'):\n",
        "    \"\"\"Get Google Trends data for Sri Lanka\"\"\"\n",
        "    try:\n",
        "        pytrends = TrendReq(hl='en-US', tz=360)\n",
        "        trending = pytrends.trending_searches(pn=geo.lower())\n",
        "\n",
        "        trends = []\n",
        "        for idx, trend in enumerate(trending[0].head(20).values):\n",
        "            trend_data = {\n",
        "                'rank': idx + 1,\n",
        "                'keyword': trend[0] if isinstance(trend, list) else str(trend),\n",
        "                'geo': geo,\n",
        "                'source': 'Google Trends',\n",
        "                'scraped_at': datetime.utcnow().isoformat()\n",
        "            }\n",
        "            trends.append(trend_data)\n",
        "\n",
        "        return trends\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting Google Trends: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Get trending searches\n",
        "trends = get_google_trends('LK')\n",
        "print(f\"‚úÖ Retrieved {len(trends)} trending searches\")\n",
        "\n",
        "# Display top trends\n",
        "if trends:\n",
        "    df_trends = pd.DataFrame(trends)\n",
        "    print(\"\\nüìà Top 10 Trending Searches in Sri Lanka:\")\n",
        "    print(df_trends[['rank', 'keyword']].head(10).to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgzshLRHMhen"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYFXRu4GMhen",
        "outputId": "d8d30a95-98ff-4097-d4d8-41da13e54ab6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Signal detection completed!\n",
            "üìä Articles with signals: 1\n"
          ]
        }
      ],
      "source": [
        "# Signal keywords mapping (from SSD - Signal Specification Document)\n",
        "SIGNAL_KEYWORDS = {\n",
        "    \"Government Policy Announcements\": [\"policy\", \"tax\", \"cabinet approves\", \"budget\", \"government policy\"],\n",
        "    \"Fuel Shortage Mentions\": [\"fuel shortage\", \"petrol shortage\", \"diesel shortage\", \"fuel crisis\", \"fuel queues\"],\n",
        "    \"Inflation Mentions\": [\"inflation\", \"price increase\", \"cost of living\", \"inflation rate\", \"cpi\"],\n",
        "    \"Dollar Rate Discussions\": [\"dollar rate\", \"usd rate\", \"exchange rate\", \"rupee dollar\", \"currency rate\"],\n",
        "    \"Power Outages (CEB)\": [\"power outage\", \"power cut\", \"load shedding\", \"ceb\", \"electricity cut\"],\n",
        "    \"Flood Warnings\": [\"flood\", \"flooding\", \"flood warning\", \"flood alert\", \"flash flood\"],\n",
        "    \"Public Protests & Demonstrations\": [\"protest\", \"demonstration\", \"rally\", \"march\", \"protesters\"],\n",
        "    \"Rainfall Alerts\": [\"rainfall\", \"heavy rain\", \"rain alert\", \"rainfall warning\", \"monsoon\"],\n",
        "    \"Crime & Safety Alerts\": [\"crime\", \"robbery\", \"theft\", \"murder\", \"safety alert\"],\n",
        "    \"Tourism Search Trend (Google Trends)\": [\"tourism\", \"tourist\", \"visitor\", \"travel sri lanka\", \"hotel booking\"],\n",
        "    # Add more as needed\n",
        "}\n",
        "\n",
        "def detect_signals(text, title=\"\"):\n",
        "    \"\"\"Detect signals from text using keyword matching (SSD-based)\"\"\"\n",
        "    full_text = f\"{title} {text}\".lower()\n",
        "    detected = []\n",
        "\n",
        "    for signal_name, keywords in SIGNAL_KEYWORDS.items():\n",
        "        matches = []\n",
        "        for keyword in keywords:\n",
        "            pattern = r'\\b' + re.escape(keyword.lower()) + r'\\b'\n",
        "            if re.search(pattern, full_text):\n",
        "                matches.append(keyword)\n",
        "\n",
        "        if matches:\n",
        "            confidence = min(0.5 + (len(matches) * 0.15), 1.0)\n",
        "            detected.append({\n",
        "                'signal_name': signal_name,\n",
        "                'confidence': round(confidence, 2),\n",
        "                'matched_keywords': matches[:5]\n",
        "            })\n",
        "\n",
        "    return detected\n",
        "\n",
        "# Detect signals in articles\n",
        "for article in all_scraped_articles[:10]:  # Test on first 10\n",
        "    signals = detect_signals(article.get('description', ''), article.get('title', ''))\n",
        "    article['detected_signals'] = signals\n",
        "\n",
        "print(\"‚úÖ Signal detection completed!\")\n",
        "print(f\"üìä Articles with signals: {sum(1 for a in all_scraped_articles[:10] if a.get('detected_signals'))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7_bmkVhMheo"
      },
      "source": [
        "## Optional: LLM Extraction (if API key available)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvOImRqPMheo",
        "outputId": "8ab3ed59-18db-4270-e5b4-bec49067b21d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing Mistral 7B on: Access to Kandy, Gampola towns in Sri Lanka restor...\n",
            "‚ö†Ô∏è API error: 410\n",
            "‚úÖ Mistral 7B extracted 0 signals\n"
          ]
        }
      ],
      "source": [
        "# Mistral 7B Instruct LLM (FREE - via Hugging Face)\n",
        "USE_LLM = True  # Set to True to use Mistral 7B (free!)\n",
        "HUGGINGFACE_API_TOKEN = os.getenv('HUGGINGFACE_API_TOKEN', '')  # Optional but recommended\n",
        "\n",
        "if USE_LLM:\n",
        "    try:\n",
        "        import requests\n",
        "\n",
        "        MISTRAL_MODEL = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "        API_URL = f\"https://api-inference.huggingface.co/models/{MISTRAL_MODEL}\"\n",
        "\n",
        "        def extract_signals_mistral(text, title=\"\"):\n",
        "            \"\"\"Extract signals using Mistral 7B Instruct (FREE!)\"\"\"\n",
        "            prompt = f\"\"\"Analyze this news article and extract relevant signals from the 40 PESTLE signals.\n",
        "\n",
        "Title: {title}\n",
        "Content: {text[:1000]}\n",
        "\n",
        "Available signals: {', '.join(SIGNALS[:15])}...\n",
        "\n",
        "Return a JSON object with a \"signals\" array. Each signal should have:\n",
        "- signal_name (must match one from the list)\n",
        "- confidence (0-1)\n",
        "- pestle_category\n",
        "- swot_category\n",
        "- severity_estimate (0-1)\n",
        "\n",
        "Format: {{\"signals\": [{{\"signal_name\": \"...\", \"confidence\": 0.8, ...}}]}}\"\"\"\n",
        "\n",
        "            # Format for Mistral Instruct\n",
        "            formatted_prompt = f\"<s>[INST] {prompt} [/INST]\"\n",
        "\n",
        "            headers = {}\n",
        "            if HUGGINGFACE_API_TOKEN:\n",
        "                headers[\"Authorization\"] = f\"Bearer {HUGGINGFACE_API_TOKEN}\"\n",
        "\n",
        "            payload = {\n",
        "                \"inputs\": formatted_prompt,\n",
        "                \"parameters\": {\n",
        "                    \"max_new_tokens\": 1000,\n",
        "                    \"temperature\": 0.3,\n",
        "                    \"return_full_text\": False\n",
        "                }\n",
        "            }\n",
        "\n",
        "            try:\n",
        "                response = requests.post(API_URL, headers=headers, json=payload, timeout=60)\n",
        "\n",
        "                if response.status_code == 200:\n",
        "                    result = response.json()\n",
        "                    if isinstance(result, list) and len(result) > 0:\n",
        "                        content = result[0].get('generated_text', '')\n",
        "                    else:\n",
        "                        content = str(result)\n",
        "\n",
        "                    # Extract JSON from response\n",
        "                    import re\n",
        "                    json_match = re.search(r'\\{.*\\}', content, re.DOTALL)\n",
        "                    if json_match:\n",
        "                        parsed = json.loads(json_match.group())\n",
        "                        return parsed.get('signals', [])\n",
        "                    return []\n",
        "                elif response.status_code == 503:\n",
        "                    print(\"‚ö†Ô∏è Model is loading, please wait a moment and try again\")\n",
        "                    return []\n",
        "                else:\n",
        "                    print(f\"‚ö†Ô∏è API error: {response.status_code}\")\n",
        "                    return []\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è LLM extraction error: {str(e)}\")\n",
        "                return []\n",
        "\n",
        "        # Test on one article\n",
        "        if all_scraped_articles:\n",
        "            test_article = all_scraped_articles[0]\n",
        "            print(f\"Testing Mistral 7B on: {test_article.get('title', '')[:50]}...\")\n",
        "            llm_signals = extract_signals_mistral(\n",
        "                test_article.get('description', ''),\n",
        "                test_article.get('title', '')\n",
        "            )\n",
        "            print(f\"‚úÖ Mistral 7B extracted {len(llm_signals)} signals\")\n",
        "            if llm_signals:\n",
        "                print(f\"   Example: {llm_signals[0].get('signal_name', 'N/A')}\")\n",
        "    except ImportError:\n",
        "        print(\"‚ö†Ô∏è Requests library not available\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è LLM extraction disabled\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dxpINbSMhep"
      },
      "source": [
        "## Save Data & Prepare for TensorFlow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNEg6bCfMhep",
        "outputId": "72985351-8ed0-4f57-df0a-327195034813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Saved 20 items to /content/collected_data_20251129_154143.json\n",
            "\n",
            "üìä Data Summary:\n",
            "Total items: 20\n",
            "\n",
            "Sources:\n",
            "source\n",
            "EconomyNext    20\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Combine all data\n",
        "all_data = all_scraped_articles + trends\n",
        "\n",
        "# Save to JSON\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "output_file = f'/content/collected_data_{timestamp}.json'\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(all_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"‚úÖ Saved {len(all_data)} items to {output_file}\")\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(all_data)\n",
        "print(f\"\\nüìä Data Summary:\")\n",
        "print(f\"Total items: {len(df)}\")\n",
        "if 'source' in df.columns:\n",
        "    print(f\"\\nSources:\\n{df['source'].value_counts()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEtE5kuCMheq",
        "outputId": "ec88abd5-4a00-4aeb-b7e1-d2df233d69a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ TensorFlow 2.19.0 imported\n",
            "GPU Available: True\n",
            "‚úÖ Text preprocessing completed - ready for TensorFlow models!\n"
          ]
        }
      ],
      "source": [
        "# Import TensorFlow for future ML models\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(f\"‚úÖ TensorFlow {tf.__version__} imported\")\n",
        "print(f\"GPU Available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n",
        "\n",
        "# Text preprocessing for TensorFlow\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Basic text preprocessing\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    return text.lower().strip()\n",
        "\n",
        "# Preprocess text\n",
        "if 'description' in df.columns:\n",
        "    df['processed_text'] = df['description'].apply(preprocess_text)\n",
        "elif 'text' in df.columns:\n",
        "    df['processed_text'] = df['text'].apply(preprocess_text)\n",
        "\n",
        "print(\"‚úÖ Text preprocessing completed - ready for TensorFlow models!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0mgDxHnMheq"
      },
      "source": [
        "## Summary\n",
        "\n",
        "‚úÖ **Data Collection Complete!**\n",
        "\n",
        "- **Method 1 (Scraping)**: RSS feeds from Ada Derana & EconomyNext\n",
        "- **Method 2 (API)**: Google Trends for Sri Lanka\n",
        "- **Method 3 (Signal Detection)**: Keyword-based detection from SSD\n",
        "\n",
        "**Next Steps** (from Workflow.md):\n",
        "- Step 3: NLP Preprocessing (SBERT embeddings, clustering)\n",
        "- Step 4: Deep Learning Models (BERT, LSTM)\n",
        "- Step 5: Model Training\n",
        "- Step 6: Model Evaluation\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
